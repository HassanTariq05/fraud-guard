# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L_k76CiE8-Pm4c1CkWKUiVspNExmdcRM
"""

!pip install pandas numpy scikit-learn matplotlib seaborn xgboost

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from xgboost import XGBClassifier
import tkinter as tk
from tkinter import messagebox

# Load dataset
df = pd.read_csv('/content/creditcard.csv')
print("Dataset Shape:", df.shape)
print("\nFirst 5 Rows:\n", df.head())
print("\nDataset Info:\n")
df.info()
print("\nClass Distribution:\n", df['Class'].value_counts())

# Check for missing values
print("Missing Values:\n", df.isnull().sum())

# Scale 'Amount' and 'Time' features
scaler = StandardScaler()
df['Scaled_Amount'] = scaler.fit_transform(df[['Amount']])
df['Scaled_Time'] = scaler.fit_transform(df[['Time']])

# Drop original 'Amount' and 'Time' columns
df = df.drop(['Amount', 'Time'], axis=1)

# Exploratory Data Analysis (EDA)
# 1. Class distribution plot
plt.figure(figsize=(6, 4))
sns.countplot(x='Class', data=df)
plt.title('Class Distribution (0: Non-Fraud, 1: Fraud)')
plt.show()

# 2. Correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), cmap='coolwarm', annot=False)
plt.title('Correlation Heatmap')
plt.show()

# 3. Boxplot of Scaled_Amount by Class
plt.figure(figsize=(8, 6))
sns.boxplot(x='Class', y='Scaled_Amount', data=df)
plt.title('Scaled Amount by Class')
plt.show()

# Handle class imbalance using undersampling (for simplicity)
fraud = df[df['Class'] == 1]
non_fraud = df[df['Class'] == 0].sample(n=len(fraud), random_state=42)
balanced_df = pd.concat([fraud, non_fraud])

# Verify balanced dataset
print("Balanced Dataset Class Distribution:\n", balanced_df['Class'].value_counts())

# Prepare data for modeling
X = balanced_df.drop('Class', axis=1)
y = balanced_df['Class']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize models
models = {
    'Logistic Regression': LogisticRegression(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
}

# Train and evaluate models
for name, model in models.items():
    print(f"\nTraining {name}...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Evaluation metrics
    print(f"\n{name} Results:")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Precision:", precision_score(y_test, y_pred))
    print("Recall:", recall_score(y_test, y_pred))
    print("F1 Score:", f1_score(y_test, y_pred))
    print("\nClassification Report:\n", classification_report(y_test, y_pred))

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix - {name}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

